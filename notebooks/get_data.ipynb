{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3038ce07",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "**Ojective:** Download 100 rows of new currency pairs data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import datetime\n",
    "import time\n",
    "from polygon import RESTClient\n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbcf364f",
   "metadata": {},
   "source": [
    "## Raw and Aggregated Tables\n",
    "\n",
    "These are the raw and agg tables. The values in raw tables will delete every 6 minutes and aggregate their value into the agg tables.\n",
    "\n",
    "### **Table Attributes**\n",
    "\n",
    "**Raw Table:** ticktime, fxrate, inserttime\n",
    "\n",
    "**Agg Table:** \n",
    "1. Timestamp (ùëá)\n",
    "2. Mean price (ùëÉ),\n",
    "3. Maximum price (MAX),\n",
    "4. Minimum price (MIN),\n",
    "5. Volatility (VOL = (MAX‚ÄìMIN)/ùëÉ),\n",
    "6. Fractal dimension (FD) calculated with a counting process on a modified Ketner Channel            \n",
    "7. Return (ùëÖùëÖùëñùëñ=(ùëÉùëñ‚àíùëÉùëñ‚àí1)ùëÉùëñ‚àí1‚ÅÑ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095050f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to clean the outlier of in the raw data values. \n",
    "def clean_outlier(pd_series):\n",
    "    '''\n",
    "    Input a pandas series, output a cleaned pandas series\n",
    "    '''\n",
    "    Q1 = pd_series.quantile(0.25)\n",
    "    Q3 = pd_series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    minimum_val = Q1 - 1.5*IQR\n",
    "    maximum_val = Q3 + 1.5*IQR\n",
    "    output = pd_series[(pd_series >= minimum_val) & (pd_series <= maximum_val)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "# count how many items in a list, for counting N for the fd\n",
    "def count_range_in_list(li, min_, max_):\n",
    "    count = 0\n",
    "    for i in li:\n",
    "        if (i > min_) and (i < max_):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Function slightly modified from polygon sample code to format the date string \n",
    "def ts_to_datetime(ts) -> str:\n",
    "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Function which clears the raw data tables once we have aggregated the data in a 6 minute interval\n",
    "def reset_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"DROP TABLE \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the raw, unaggregated price data for each currency pair in the SQLite database\n",
    "def initialize_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the (6 min interval) aggregated price data for each currency pair in the SQLite database            \n",
    "def initialize_aggregated_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\n",
    "                              '''_agg(inserttime text, avgfxrate  numeric, minfxrate numeric, \n",
    "                                 maxfxrate numeric, vol numeric, fd numeric, \n",
    "                                 return_r numeric); ''' ))\n",
    "            \n",
    "            \n",
    "# This function is called every 6 minutes to aggregate the data, store it in the aggregate table, \n",
    "# and then delete the raw data\n",
    "def aggregate_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            \n",
    "            #get the fxrate in our raw data for fd calculation \n",
    "            fxrate_res = conn.execute(text(\"SELECT fxrate FROM \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            fxrate_data = [row.fxrate for row in fxrate_res]\n",
    "            # use pandas to clean the data\n",
    "            fxrate_series = pd.Series(fxrate_data)\n",
    "            clean_fxrate =clean_outlier(fxrate_series)\n",
    "            # calcuate avg, count, min, max , and vol in the clean data.\n",
    "            avg_price = clean_fxrate.mean()\n",
    "            tot_count = clean_fxrate.count()\n",
    "            min_price = clean_fxrate.min()\n",
    "            max_price = clean_fxrate.max()\n",
    "            # update the VOL as VOL = {MAX‚ÄìMIN}/ùëÉùëÉ)\n",
    "            vol = (max_price - min_price)/avg_price\n",
    "\n",
    "            # check if empty: # This line can find out which api break in our currency pair. \n",
    "            if tot_count == 0:\n",
    "                print(curr[0]+curr[1]+\" has no value\")\n",
    "            \n",
    "            # add keltner channel (KCUB and KCLB) into our table, append the keltner channel values in the lists.\n",
    "            kcub_values = []\n",
    "            kclb_values = []\n",
    "            for i in range(100):\n",
    "                kcub_values.append(avg_price + (i+1)*0.025*vol)\n",
    "                kclb_values.append(avg_price - (i+1)*0.025*vol)\n",
    "            \n",
    "            # after calculation make to series to list.  \n",
    "            fxrate_data = clean_fxrate.to_list()\n",
    "            # then we will slice the data into increasing and decreasing range\n",
    "            increase_bound = np.split(fxrate_data, np.where(np.diff(fxrate_data) < 0)[0]+1)\n",
    "            increase_revert_bound = [(increase_bound[i][0], increase_bound[i-1][-1]) for i in range(1, len(increase_bound))]\n",
    "            \n",
    "            \n",
    "            # get FD values\n",
    "            # first make copy of the list\n",
    "            kcub_values_copy = kcub_values.copy()\n",
    "            kclb_values_copy = kclb_values.copy()\n",
    "            kcub_values_copy.extend(kclb_values_copy)\n",
    "            keltner_values = kcub_values_copy.copy()\n",
    "            \n",
    "            if not curr[2]:\n",
    "                fd = None\n",
    "                curr[2].append(keltner_values)\n",
    "            else:\n",
    "                if vol == 0:\n",
    "                    fd = 0\n",
    "                    curr[2].append(keltner_values)\n",
    "                else:\n",
    "                    # get the N for fd which is keltner_tot_count\n",
    "                    N_count = 0\n",
    "                    for i in increase_bound:\n",
    "                        N_count += count_range_in_list(curr[2][-1], i[0], i[-1])\n",
    "                    for i in increase_revert_bound:\n",
    "                        N_count += count_range_in_list(curr[2][-1], i[0], i[-1])\n",
    "                    # after we calculate N_count, we can calculate fd by dividing the vol\n",
    "                    fd = N_count / vol\n",
    "                    curr[2].append(keltner_values)\n",
    "            \n",
    "            # calculate the return r defined as ùëüùëñ = (ùëÉùëñ ‚àí ùëÉ(ùëñ‚àí1))‚ÅÑ(ùëÉùëñ‚àí1).\n",
    "            if not curr[-1]:\n",
    "                return_r = None\n",
    "                curr[-1].append(avg_price)\n",
    "            else:\n",
    "                if (curr[-1][-1] == 0) or (avg_price - curr[-1][-1] ==0):\n",
    "                    return_r = 0\n",
    "                    curr[-1].append(avg_price)\n",
    "                else:\n",
    "                    return_r = (avg_price - (curr[-1][-1]))/(curr[-1][-1])\n",
    "                    curr[-1].append(avg_price)\n",
    "\n",
    "            # get ticktime for the raw table\n",
    "            date_res = conn.execute(text(\"SELECT MAX(ticktime) as last_date FROM \"+curr[0]+curr[1]+\"_raw;\"))   \n",
    "            for row in date_res:\n",
    "                last_date = row.last_date\n",
    "\n",
    "            #insert the values into the agg tables\n",
    "            conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                              '''_agg VALUES (:inserttime, :avgfxrate, :minfxrate, :maxfxrate, :vol, :fd, :return_r);'''),\n",
    "                         {'inserttime':last_date ,'avgfxrate': avg_price, 'minfxrate': min_price,  'maxfxrate': max_price, \n",
    "                          'vol': vol, 'fd': fd, 'return_r': return_r})\n",
    "            \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8c1d462",
   "metadata": {},
   "source": [
    "## Main Function \n",
    "\n",
    "Our main function will execute the previous tables in order to generate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ee4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This main function repeatedly calls the polygon api every 1 seconds for 10 hours \n",
    "# and stores the results.\n",
    "def main(currency_pairs):\n",
    "    # The api key given by the professor\n",
    "    key = input(\"Enter Your API:\")\n",
    "   \n",
    "    # Number of list iterations - each one should last about 1 second\n",
    "    count = 0\n",
    "    agg_count = 0\n",
    "    times_count = 0\n",
    "    \n",
    "    # Create an engine to connect to the database; setting echo to false should stop it from logging in std.out\n",
    "    engine = create_engine(\"sqlite+pysqlite:///../data/test2.db\", echo=False, future=True)\n",
    "    \n",
    "    # Create the needed tables in the database\n",
    "    initialize_raw_data_tables(engine,currency_pairs)\n",
    "    initialize_aggregated_tables(engine,currency_pairs)\n",
    "    \n",
    "    # Open a RESTClient for making the api calls\n",
    "    client = RESTClient(key)\n",
    "    # Loop that runs until the total duration of the program hits 10 hours. \n",
    "    while count <= 36000: # 36000 seconds = 10 hours \n",
    "        \n",
    "        # Make a check to see if 6 minutes has been reached or not\n",
    "        if agg_count == 360:\n",
    "            # Aggregate the data and clear the raw data tables\n",
    "            aggregate_raw_data_tables(engine,currency_pairs)\n",
    "            reset_raw_data_tables(engine,currency_pairs)\n",
    "            agg_count = 0\n",
    "            times_count += 1\n",
    "            print(f\"finish {times_count} times aggregation!\")\n",
    "\n",
    "        # Only call the api every 1 second, so wait here for 0.75 seconds, because the \n",
    "        # code takes about .15 seconds to run\n",
    "        time.sleep(0.75)\n",
    "\n",
    "        # Increment the counters\n",
    "        count += 1\n",
    "        agg_count +=1\n",
    "\n",
    "\n",
    "        # Loop through each currency pair\n",
    "        for currency in currency_pairs:\n",
    "            # Set the input variables to the API\n",
    "            from_ = currency[0]\n",
    "            to = currency[1]\n",
    "\n",
    "            # Call the API with the required parameters\n",
    "            try:\n",
    "                resp = client.get_real_time_currency_conversion(from_, to, amount=100, precision=2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # This gets the Last Trade object defined in the API Resource\n",
    "            last_trade = resp.last\n",
    "\n",
    "            # Format the timestamp from the result\n",
    "            dt = ts_to_datetime(last_trade.timestamp)\n",
    "\n",
    "            # Get the current time and format it\n",
    "            insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            # Calculate the price by taking the average of the bid and ask prices\n",
    "            avg_price = (last_trade.bid + last_trade.ask)/2\n",
    "\n",
    "            # Write the data to the SQLite database, raw data tables\n",
    "            with engine.begin() as conn:\n",
    "                conn.execute(text(\"INSERT INTO \"+from_+to+\"_raw(ticktime, fxrate, inserttime) VALUES (:ticktime, :fxrate, :inserttime)\"),[{\"ticktime\": dt, \"fxrate\": avg_price, \"inserttime\": insert_time}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a638af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# A dictionary defining the set of currency pairs we will be pulling data for\n",
    "currency_pairs = [[\"EUR\",\"USD\",[], []],\n",
    "                  [\"GBP\",\"USD\",[], []],\n",
    "                  [\"USD\",\"CHF\",[], []],\n",
    "                  [\"USD\",\"CAD\",[], []],\n",
    "                  [\"USD\",\"HKD\",[], []],\n",
    "                  [\"USD\",\"AUD\",[], []],\n",
    "                  [\"USD\",\"NZD\",[], []],\n",
    "                  [\"USD\",\"SGD\",[], []]]\n",
    "\n",
    "# Run the main data collection loop\n",
    "main(currency_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf6434c5a1aa7c8e434dd054297a02391e6efb1cc4c519f6d78eae818bb65a96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
