{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd0f8120",
   "metadata": {},
   "source": [
    "# Trailing Stops\n",
    "\n",
    "**Ojective:** Build an optimized real-time trailing-stop-strategy, and use our model prediction to make real-time investment decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import datetime\n",
    "import time\n",
    "from polygon import RESTClient\n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import pycaret\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdc222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the values that we got by sorting vol and fd for modeling \n",
    "\n",
    "dic_vol={'EURUSD': [0.0004281211142476265, 0.0004281211142476265],\n",
    " 'GBPUSD': [0.0004966384844507656, 0.0004966384844507656],\n",
    " 'USDCHF': [0.00042780905428066956, 0.00042780905428066956],\n",
    " 'USDCAD': [0.0003699360646692225, 0.0003699360646692225],\n",
    " 'USDHKD': [6.876542096790575e-05, 6.876542096790575e-05],\n",
    " 'USDAUD': [0.000666613601077178, 0.000666613601077178],\n",
    " 'USDNZD': [0.0005482998171061228, 0.0005482998171061228],\n",
    " 'USDSGD': [0.0002951453297140402, 0.0002951453297140402]}\n",
    "\n",
    "dic_fd={'EURUSD': [853594.7712419365, 1547680.8777432258],\n",
    " 'GBPUSD': [666361.329745896, 1212260.5721637346],\n",
    " 'USDCHF': [944561.0899999292, 2031250.0000000827],\n",
    " 'USDCAD': [866338.8172116696, 1776093.2312128684],\n",
    " 'USDHKD': [877566.5399239843, 10200033.39031332],\n",
    " 'USDAUD': [592503.5178437203, 1376526.7708181816],\n",
    " 'USDNZD': [294972.55499312916, 670718.232044248],\n",
    " 'USDSGD': [1299890.5394999508, 2774999.999998765]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db7dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to record the previous error \n",
    "previous_error = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbcf364f",
   "metadata": {},
   "source": [
    "## Raw and Aggregated Tables\n",
    "\n",
    "These are the raw and agg tables. The values in raw tables will delete every 6 minutes and aggregate their value into the agg tables.\n",
    "\n",
    "### **Table Attributes**\n",
    "\n",
    "**Raw Table:** ticktime, fxrate, inserttime\n",
    "\n",
    "**Agg Table:** \n",
    "1. Timestamp (ð‘‡)\n",
    "2. Mean price (ð‘ƒ),\n",
    "3. Maximum price (MAX),\n",
    "4. Minimum price (MIN),\n",
    "5. Volatility (VOL = (MAXâ€“MIN)/ð‘ƒ),\n",
    "6. Fractal dimension (FD) calculated with a counting process on a modified Ketner Channel            \n",
    "7. Return (ð‘…ð‘…ð‘–ð‘–=(ð‘ƒð‘–âˆ’ð‘ƒð‘–âˆ’1)ð‘ƒð‘–âˆ’1â„."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095050f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to clean the outlier of in the raw data values. \n",
    "def clean_outlier(pd_series):\n",
    "    '''\n",
    "    Input a pandas series, output a cleaned pandas series\n",
    "    '''\n",
    "    Q1 = pd_series.quantile(0.25)\n",
    "    Q3 = pd_series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    minimum_val = Q1 - 1.5*IQR\n",
    "    maximum_val = Q3 + 1.5*IQR\n",
    "    output = pd_series[(pd_series >= minimum_val) & (pd_series <= maximum_val)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "# count how many item in a list, for counting N for the fd\n",
    "def count_range_in_list(li, min_, max_):\n",
    "    count = 0\n",
    "    for i in li:\n",
    "        if (i >= min_) and (i <= max_):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Function slightly modified from polygon sample code to format the date string \n",
    "def ts_to_datetime(ts) -> str:\n",
    "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Function which clears the raw data tables once we have aggregated the data in a 6 minute interval\n",
    "def reset_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"DROP TABLE \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the raw, unaggregated price data for each currency pair in the SQLite database\n",
    "def initialize_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_raw(ticktime text, fxrate  numeric, inserttime text);\"))\n",
    "\n",
    "# This creates a table for storing the (6 min interval) aggregated price data for each currency pair in the SQLite database            \n",
    "def initialize_aggregated_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\n",
    "                              '''_agg(inserttime text, avgfxrate numeric, minfxrate numeric, \n",
    "                                 maxfxrate numeric, vol numeric, fd numeric, \n",
    "                                 return_r numeric); ''' ))\n",
    "            \n",
    "            \n",
    "# This function is called every 6 minutes to aggregate the data, store it in the aggregate table, \n",
    "# and then delete the raw data\n",
    "def aggregate_raw_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            \n",
    "            #get the fxrate in our raw data for fd calculation \n",
    "            fxrate_res = conn.execute(text(\"SELECT fxrate FROM \"+curr[0]+curr[1]+\"_raw;\"))\n",
    "            fxrate_data = [row.fxrate for row in fxrate_res]\n",
    "            # use pandas to clean the data\n",
    "            fxrate_series = pd.Series(fxrate_data)\n",
    "            clean_fxrate =clean_outlier(fxrate_series)\n",
    "            # calcuate avg, count, min, max , and vol in the clean data.\n",
    "            avg_price = clean_fxrate.mean()\n",
    "            tot_count = clean_fxrate.count()\n",
    "            min_price = clean_fxrate.min()\n",
    "            max_price = clean_fxrate.max()\n",
    "            vol = (max_price - min_price)/avg_price\n",
    "\n",
    "            # check if empty:\n",
    "            if tot_count == 0:\n",
    "                print(curr[0]+curr[1]+\" has no value\")\n",
    "            \n",
    "            # add keltner channel (KCUB and KCLB) into our table, put name and values in the dictionary\n",
    "            kcub_values = []\n",
    "            kclb_values = []\n",
    "            for i in range(100):\n",
    "                kcub_values.append(avg_price + (i+1)*0.025*vol)\n",
    "                kclb_values.append(avg_price - (i+1)*0.025*vol)\n",
    "            \n",
    "            # after calculation make to series to list.  \n",
    "            fxrate_data = clean_fxrate.to_list()\n",
    "            # then we will slice the data into increasing and decreasing range\n",
    "            increase_bound = np.split(fxrate_data, np.where(np.diff(fxrate_data) < 0)[0]+1)\n",
    "            increase_revert_bound = [(increase_bound[i][0], increase_bound[i-1][-1]) for i in range(1, len(increase_bound))]\n",
    "            \n",
    "            \n",
    "            # get FD values\n",
    "            # first make copy of the list\n",
    "            kcub_values_copy = kcub_values.copy()\n",
    "            kclb_values_copy = kclb_values.copy()\n",
    "            kcub_values_copy.extend(kclb_values_copy)\n",
    "            keltner_values = kcub_values_copy.copy()\n",
    "            \n",
    "            if not curr[2]:\n",
    "                fd = None\n",
    "                curr[2].append(keltner_values)\n",
    "            else:\n",
    "                if vol == 0:\n",
    "                    fd = 0\n",
    "                    curr[2].append(keltner_values)\n",
    "                else:\n",
    "                    # get the N for fd which is keltner_tot_count\n",
    "                    N_count = 0\n",
    "                    for i in increase_bound:\n",
    "                        N_count += count_range_in_list(curr[2][-1], i[0], i[-1])\n",
    "                    for i in increase_revert_bound:\n",
    "                        N_count += count_range_in_list(curr[2][-1], i[0], i[-1])\n",
    "                    # after we calculate N_count, we can calculate fd by dividing the vol\n",
    "                    fd = N_count / vol\n",
    "                    curr[2].append(keltner_values)\n",
    "            \n",
    "            # calculate the return r defined as ð‘Ÿð‘– = (ð‘ƒð‘– âˆ’ ð‘ƒ(ð‘–âˆ’1))â„(ð‘ƒð‘–âˆ’1).\n",
    "            if not curr[-1]:\n",
    "                return_r = None\n",
    "                curr[-1].append(avg_price)\n",
    "            else:\n",
    "                if (curr[-1][-1] == 0) or (avg_price - curr[-1][-1] ==0):\n",
    "                    return_r = 0\n",
    "                    curr[-1].append(avg_price)\n",
    "                else:\n",
    "                    return_r = (avg_price - (curr[-1][-1]))/(curr[-1][-1])\n",
    "                    curr[-1].append(avg_price)\n",
    "\n",
    "            # get ticktime for the raw table\n",
    "            date_res = conn.execute(text(\"SELECT MAX(ticktime) as last_date FROM \"+curr[0]+curr[1]+\"_raw;\"))   \n",
    "            for row in date_res:\n",
    "                last_date = row.last_date\n",
    "\n",
    "            #insert the values into the agg tables\n",
    "            conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                              '''_agg VALUES (:inserttime, :avgfxrate, :minfxrate, :maxfxrate, :vol, :fd, :return_r);'''),\n",
    "                         {'inserttime':last_date ,'avgfxrate': avg_price, 'minfxrate': min_price,  'maxfxrate': max_price, \n",
    "                          'vol': vol, 'fd': fd, 'return_r': return_r})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7445a6e",
   "metadata": {},
   "source": [
    "## Modeling Tables\n",
    "\n",
    "We will create a table for our modeling prediction. (The table is running every 6 minutes and predict the return values from the agg table)\n",
    "\n",
    "### **Table Attributes**\n",
    "\n",
    "**MLResult Table:** Predicted return, Actual Return, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136f832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates model output tables with the attributes of predicted return, the actual return, and the error.\n",
    "def initialize_model_output_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_MLResult(predicted_return numeric, actual_return numeric, error numeric);\"))\n",
    "\n",
    "# This function will execute our models that were predicted from data_engineering_modeling.ipynb, and insert our result into our modeling tables.\n",
    "def aggregate_agg_data_to_ML(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs:\n",
    "            df = pd.read_sql_table(curr[0]+curr[1]+\"_agg\",conn)\n",
    "            # Check and see if it's the first entry. If it's true, there is no return.\n",
    "            if df['avgfxrate'].count() == 1:\n",
    "                predicted_return = None\n",
    "                actual_return = None\n",
    "                error = None \n",
    "                # insert value into our database\n",
    "                conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                              '''_MLResult VALUES (:predicted_return, :actual_return, :error );'''),\n",
    "                         {'predicted_return':predicted_return, 'actual_return':actual_return, 'error':error})\n",
    "            else:\n",
    "                training = df[['avgfxrate', 'vol','fd','return_r']].iloc[-1:]\n",
    "                training_copy = training.copy()\n",
    "\n",
    "                # Build a recursive function to run in parse_vol_fd function in order to \n",
    "                # access our dictionary in to begining, and define the new threshold for parsing fd and vol into [1,2,3]\n",
    "                def get_thres_vol(curr):\n",
    "                    global dic_vol\n",
    "                    thres1 = dic_vol[curr[0]+curr[1]][0]\n",
    "                    thres2 = dic_vol[curr[0]+curr[1]][1]\n",
    "                    return [thres1,thres2]\n",
    "\n",
    "                def get_thres_fd(curr):\n",
    "                    global dic_fd\n",
    "                    thres1 = dic_fd[curr[0]+curr[1]][0]\n",
    "                    thres2 = dic_fd[curr[0]+curr[1]][1]\n",
    "                    return [thres1,thres2]\n",
    "\n",
    "                # define a function to put a new series to our training dataframe\n",
    "                def parse_vol(series, curr):\n",
    "                    thres1 = get_thres_vol(curr)[0]\n",
    "                    thres2 = get_thres_vol(curr)[1]\n",
    "                    if series <= thres1:\n",
    "                        return 1\n",
    "                    if series <= thres2:\n",
    "                        return 2\n",
    "                    else:\n",
    "                        return 3\n",
    "\n",
    "                def parse_fd(series, curr):\n",
    "                    thres1 = get_thres_fd(curr)[0]\n",
    "                    thres2 = get_thres_fd(curr)[1]\n",
    "                    if series <= thres1:\n",
    "                        return 1\n",
    "                    if series <= thres2:\n",
    "                        return 2\n",
    "                    else:\n",
    "                        return 3\n",
    "                \n",
    "                training['vol_rank'] = training['vol'].apply(parse_vol, args=(curr,))\n",
    "                training['fd_rank'] = training['fd'].apply(parse_fd, args=(curr,))\n",
    "\n",
    "\n",
    "                # Get our training dataframe ready for prediction\n",
    "                training = training[['avgfxrate', 'vol_rank', 'fd_rank']]\n",
    "                #load our model\n",
    "                model = load_model(f'../models/{curr[0]}{curr[1]}')\n",
    "                # make prediction \n",
    "                prediction = predict_model(model, data=training)\n",
    "                # print(prediction)\n",
    "\n",
    "                predicted_return = float(prediction['prediction_label'].values)\n",
    "                # we need to divide the predicted value by 100,000 to get the actual prediction\n",
    "                predicted_return = predicted_return/100000\n",
    "                actual_return = float(training_copy['return_r'].values)\n",
    "                error = predicted_return - actual_return\n",
    "\n",
    "                # insert value into our database\n",
    "                conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                              '''_MLResult VALUES (:predicted_return, :actual_return, :error );'''),\n",
    "                         {'predicted_return':predicted_return, 'actual_return':actual_return, 'error':error})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7eac47",
   "metadata": {},
   "source": [
    "## Trailing Stops Tables\n",
    "\n",
    "This is the trailing stops tables session. We have go long and go short strategys. In here, I choose 4 currency pairs go long and 4 currency pairs go short. \n",
    "In each hour, we will make investment decision base on our model predictions, our previous errors, and our actual return. \n",
    "\n",
    "### **Table Attributes**\n",
    "\n",
    "**Long Tables:** Balance, Profit_Loss, Status\n",
    "\n",
    "**Short Tables:** Balance, Profit_Loss, Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf49af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables for trailing stops project\n",
    "def initialize_trailing_stops_data_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs[:4]:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_long(balance numeric, profit_loss numeric, status text);\"))\n",
    "        for curr in currency_pairs[4:]:\n",
    "            conn.execute(text(\"CREATE TABLE \"+curr[0]+curr[1]+\"_short(balance numeric, profit_loss numeric, status text);\"))\n",
    "\n",
    "# The follow two function will aggregate the data for trailing tables\n",
    "# This function will fill values in the go long tables.\n",
    "def agg_for_trailing_stops_data_long_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:\n",
    "        for curr in currency_pairs[:4]:\n",
    "            # Init layer\n",
    "            layer = {1: -0.0025, 2: -0.0015, 3: -0.001, 4: -0.0005, 5: -0.0005, 6: -0.0005,7 : -0.0005,\n",
    "                    8: -0.0005, 9: -0.0005, 10: -0.0005}\n",
    "            # check which layer that we are in\n",
    "            count_row = conn.execute(text(\"SELECT count(*) AS count_ FROM \"+curr[0]+curr[1]+\"_long;\"))\n",
    "            for row in count_row:\n",
    "                count_ = row.count_\n",
    "            layer_we_in = count_ + 1\n",
    "            \n",
    "            # first, I am going to the MLResult tables to get the actual return values and calcate the sum of last 10 values\n",
    "            df = pd.read_sql_table(curr[0]+curr[1]+\"_MLResult\",conn)\n",
    "            sum_of_actual_return = df['actual_return'][-10:].sum()\n",
    "\n",
    "            # second, sum the current predicted_return. (current)\n",
    "            sum_of_predicted_return = df['predicted_return'][-10:].sum()\n",
    "            \n",
    "            # init and check the balance\n",
    "            if count_ == 0:\n",
    "                balance = 100\n",
    "            else:\n",
    "                balance = conn.execute(text(\"SELECT balance FROM \"+curr[0]+curr[1]+\"_long;\"))\n",
    "                balance = [row.balance for row in balance][-1]\n",
    "            \n",
    "            # check if the stauts were closed, if ture break out of the current loop, jump to the next.\n",
    "            if count_ >= 1:\n",
    "                curr_status = conn.execute(text(\"SELECT status FROM \"+curr[0]+curr[1]+\"_long;\"))\n",
    "                curr_status = [row.status for row in curr_status][-1]\n",
    "                if curr_status == 'close':\n",
    "                    continue               \n",
    "                 \n",
    "            # use conditions statement to compare layer values with sum_of_actual_return\n",
    "            status = 'continue'\n",
    "            if sum_of_actual_return > layer[layer_we_in]:\n",
    "                if layer_we_in <= 4:\n",
    "                    # First to check whether the (current actual returns) are greater or smaller than O to see if we are losing or gaining money.\n",
    "                    # then compare the (current predictions with the privous errors) with (current actual returns) to see what action to take.\n",
    "                    if sum_of_actual_return > 0:\n",
    "                        try:\n",
    "                            if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) > sum_of_actual_return:\n",
    "                                profit = balance * sum_of_actual_return\n",
    "                                balance = profit + balance + 100\n",
    "                            else:\n",
    "                                profit = balance * sum_of_actual_return\n",
    "                                balance = profit + balance\n",
    "                        except:\n",
    "                            profit = balance * sum_of_actual_return\n",
    "                            balance = profit + balance + 100                 \n",
    "                    else:\n",
    "                        try:\n",
    "                            if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) > sum_of_actual_return:\n",
    "                                profit = balance * sum_of_actual_return\n",
    "                                balance = profit + balance\n",
    "                            else:\n",
    "                                profit = balance * sum_of_actual_return\n",
    "                                balance = profit + balance\n",
    "                                status = 'close'\n",
    "                        except:\n",
    "                            profit = balance * sum_of_actual_return\n",
    "                            balance = profit + balance + 100\n",
    "                    # insert values into the table\n",
    "                    conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                      '''_long VALUES (:balance, :profit_loss, :status);'''),\n",
    "                                 {'balance': balance, 'profit_loss': profit,  'status': status})\n",
    "                else:\n",
    "                    if sum_of_actual_return > 0:     \n",
    "                        profit = balance * sum_of_actual_return\n",
    "                        balance = profit + balance                         \n",
    "                    else:  \n",
    "                        if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) > sum_of_actual_return:\n",
    "                            profit = balance * sum_of_actual_return\n",
    "                            balance = profit + balance\n",
    "                        else:\n",
    "                            profit = balance * sum_of_actual_return\n",
    "                            balance = profit + balance\n",
    "                            status = 'close'\n",
    "\n",
    "                    #insert the values into the tables\n",
    "                    conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                      '''_long VALUES (:balance, :profit_loss, :status);'''),\n",
    "                                 {'balance': balance, 'profit_loss': profit,  'status': 'continue'})\n",
    "            else:\n",
    "                profit = balance * sum_of_actual_return\n",
    "                balance = profit + balance\n",
    "                status = 'close'\n",
    "                #insert the values into the tables\n",
    "                conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                  '''_long VALUES (:balance, :profit_loss, :status);'''),\n",
    "                             {'balance': balance, 'profit_loss': profit,  'status': status}) \n",
    "\n",
    "            # finally, do the sum of error (we want the privous error), so we will compute to current error and store it in the previous error dictionary for the next use.\n",
    "            sum_of_previous_error = df['error'][-10:].sum()\n",
    "            previous_error[curr[0]+curr[1]] = sum_of_previous_error\n",
    "\n",
    "# This function will fill values in the go short tables.\n",
    "def agg_for_trailing_stops_data_short_tables(engine,currency_pairs):\n",
    "    with engine.begin() as conn:        \n",
    "        for curr in currency_pairs[4:]:\n",
    "            # Init layer\n",
    "            layer = {1: 0.0025, 2: 0.0015, 3: 0.001, 4: 0.0005, 5: 0.0005, 6: 0.0005,7 : 0.0005,\n",
    "                    8: 0.0005, 9: 0.0005, 10: 0.0005}\n",
    "            # check which layer that we are in\n",
    "            count_row = conn.execute(text(\"SELECT count(*) AS count_ FROM \"+curr[0]+curr[1]+\"_short;\"))\n",
    "            for row in count_row:\n",
    "                count_ = row.count_\n",
    "            layer_we_in = count_ + 1\n",
    "            \n",
    "            # first, I am going to the MLResult tables to get the actual return values and calcate the sum of last 10 values\n",
    "            df = pd.read_sql_table(curr[0]+curr[1]+\"_MLResult\",conn)\n",
    "            sum_of_actual_return = df['actual_return'][-10:].sum()\n",
    "\n",
    "            # second, sum the current predicted_return. (current)\n",
    "            sum_of_predicted_return = df['predicted_return'][-10:].sum()\n",
    "            \n",
    "            # init and check the balance\n",
    "            if count_ == 0:\n",
    "                balance = 100\n",
    "            else:\n",
    "                balance = conn.execute(text(\"SELECT balance FROM \"+curr[0]+curr[1]+\"_short;\"))\n",
    "                balance = [row.balance for row in balance][-1]\n",
    "\n",
    "            # check if the stauts were closed, if ture break out of the current loop, jump to the next.\n",
    "            if count_ >= 1:\n",
    "                curr_status = conn.execute(text(\"SELECT status FROM \"+curr[0]+curr[1]+\"_short;\"))\n",
    "                curr_status = [row.status for row in curr_status][-1]\n",
    "                if curr_status == 'close':\n",
    "                    continue\n",
    "\n",
    "            # use conditions statement to compare layer values with sum_of_actual_return.\n",
    "            status = 'continue'\n",
    "            if sum_of_actual_return < layer[layer_we_in]:\n",
    "                if layer_we_in <= 4: \n",
    "                    # First to check whether the (current actual returns) are greater or smaller than O to see if we are losing or gaining money.\n",
    "                    # then compare the (current predictions with the privous errors) with (current actual returns) to see what action to take.\n",
    "                    if sum_of_actual_return < 0:\n",
    "                        try:\n",
    "                            if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) < sum_of_actual_return:\n",
    "                                profit = balance * sum_of_actual_return* (-1)\n",
    "                                balance = profit + balance + 100\n",
    "                            else:\n",
    "                                profit = balance * sum_of_actual_return* (-1)\n",
    "                                balance = profit + balance\n",
    "                        except:\n",
    "                            profit = balance * sum_of_actual_return* (-1)\n",
    "                            balance = profit + balance + 100                 \n",
    "                    else:\n",
    "                        try:\n",
    "                            if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) < sum_of_actual_return:\n",
    "                                profit = balance * sum_of_actual_return* (-1)\n",
    "                                balance = profit + balance\n",
    "                            else:\n",
    "                                profit = balance * sum_of_actual_return* (-1)\n",
    "                                balance = profit + balance\n",
    "                                status = 'close'\n",
    "                        except:\n",
    "                            profit = balance * sum_of_actual_return* (-1)\n",
    "                            balance = profit + balance + 100\n",
    "                    #insert the values into the tables\n",
    "                    conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                      '''_short VALUES (:balance, :profit_loss, :status);'''),\n",
    "                                 {'balance': balance, 'profit_loss': profit,  'status': status})\n",
    "                else:\n",
    "                    if sum_of_actual_return < 0:     \n",
    "                        profit = balance * sum_of_actual_return* (-1)\n",
    "                        balance = profit + balance                         \n",
    "                    else:  \n",
    "                        if (sum_of_predicted_return - previous_error[curr[0]+curr[1]]) < sum_of_actual_return:\n",
    "                            profit = balance * sum_of_actual_return* (-1)\n",
    "                            balance = profit + balance\n",
    "                        else:\n",
    "                            profit = balance * sum_of_actual_return* (-1)\n",
    "                            balance = profit + balance\n",
    "                            status = 'close'\n",
    "                    #insert the values into the tables\n",
    "                    conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                      '''_short VALUES (:balance, :profit_loss, :status);'''),\n",
    "                                 {'balance': balance, 'profit_loss': profit,  'status': status})\n",
    "            else:\n",
    "                profit = balance * sum_of_actual_return * (-1)\n",
    "                balance = profit + balance\n",
    "                status = 'close'\n",
    "                #insert the values into the tables\n",
    "                conn.execute(text(\"INSERT INTO \"+curr[0]+curr[1]+\n",
    "                                  '''_short VALUES (:balance, :profit_loss, :status);'''),\n",
    "                             {'balance': balance, 'profit_loss': profit,  'status': status})  \n",
    "            \n",
    "            # finally, do the sum of error (we want the privous error), so we will compute to current error and store it in the previous error dictionary for the next use.\n",
    "            sum_of_previous_error = df['error'][-10:].sum()\n",
    "            previous_error[curr[0]+curr[1]] = sum_of_previous_error\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8c1d462",
   "metadata": {},
   "source": [
    "## Main Function \n",
    "\n",
    "Our main function will execute the previous tables in order to generate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ee4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This main function repeatedly calls the polygon api every 1 seconds for 10 hours \n",
    "# and stores the results.\n",
    "def main(currency_pairs):\n",
    "    # The api key given by the professor\n",
    "    key = input(\"Enter Your API:\")\n",
    "   \n",
    "    # Number of list iterations - each one should last about 1 second\n",
    "    count = 0\n",
    "    agg_count = 0\n",
    "    ts_count = 0\n",
    "    times_count = 0\n",
    "    \n",
    "    # Create an engine to connect to the database; setting echo to false should stop it from logging in std.out\n",
    "    engine = create_engine(\"sqlite+pysqlite:///../data/test.db\", echo=False, future=True)\n",
    "    \n",
    "    # Create the needed tables in the database\n",
    "    initialize_raw_data_tables(engine,currency_pairs)\n",
    "    initialize_aggregated_tables(engine,currency_pairs)\n",
    "    initialize_model_output_tables(engine,currency_pairs)\n",
    "    initialize_trailing_stops_data_tables(engine,currency_pairs)\n",
    "    \n",
    "    # Open a RESTClient for making the api calls\n",
    "    client = RESTClient(key)\n",
    "    # Loop that runs until the total duration of the program hits 10 hours. \n",
    "    while count <= 36000: # 36000 seconds = 10 hours \n",
    "        \n",
    "        # Make a check to see if 6 minutes has been reached or not \n",
    "        if agg_count == 360:\n",
    "            # Aggregate the data and clear the raw data tables\n",
    "            aggregate_raw_data_tables(engine,currency_pairs)\n",
    "            reset_raw_data_tables(engine,currency_pairs)\n",
    "            # put agg value into a model prediction\n",
    "            aggregate_agg_data_to_ML(engine,currency_pairs)\n",
    "            agg_count = 0\n",
    "            times_count += 1\n",
    "            print(f\"finish {times_count} times prediction!\")\n",
    "        \n",
    "        # check if one hour has been reached \n",
    "        if ts_count == 3600:\n",
    "            # call function and aggreate for the trailing stops tables\n",
    "            agg_for_trailing_stops_data_long_tables(engine,currency_pairs)\n",
    "            agg_for_trailing_stops_data_short_tables(engine,currency_pairs)\n",
    "            ts_count = 0\n",
    "\n",
    "        # Only call the api every 1 second, so wait here for 0.75 seconds, because the \n",
    "        # code takes about .15 seconds to run\n",
    "        time.sleep(0.75)\n",
    "\n",
    "        # Increment the counters\n",
    "        count += 1\n",
    "        agg_count +=1\n",
    "        ts_count += 1\n",
    "\n",
    "        # Loop through each currency pair\n",
    "        for currency in currency_pairs:\n",
    "            # Set the input variables to the API\n",
    "            from_ = currency[0]\n",
    "            to = currency[1]\n",
    "\n",
    "            # Call the API with the required parameters\n",
    "            try:\n",
    "                resp = client.get_real_time_currency_conversion(from_, to, amount=100, precision=2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # This gets the Last Trade object defined in the API Resource\n",
    "            last_trade = resp.last\n",
    "\n",
    "            # Format the timestamp from the result\n",
    "            dt = ts_to_datetime(last_trade.timestamp)\n",
    "\n",
    "            # Get the current time and format it\n",
    "            insert_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            # Calculate the price by taking the average of the bid and ask prices\n",
    "            avg_price = (last_trade.bid + last_trade.ask)/2\n",
    "\n",
    "            # Write the data to the SQLite database, raw data tables\n",
    "            with engine.begin() as conn:\n",
    "                conn.execute(text(\"INSERT INTO \"+from_+to+\"_raw(ticktime, fxrate, inserttime) VALUES (:ticktime, :fxrate, :inserttime)\"),[{\"ticktime\": dt, \"fxrate\": avg_price, \"inserttime\": insert_time}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a638af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary defining the set of currency pairs we will be pulling data for\n",
    "currency_pairs = [[\"EUR\",\"USD\",[], []],\n",
    "                  [\"GBP\",\"USD\",[], []],\n",
    "                  [\"USD\",\"CHF\",[], []],\n",
    "                  [\"USD\",\"CAD\",[], []],\n",
    "                  [\"USD\",\"HKD\",[], []],\n",
    "                  [\"USD\",\"AUD\",[], []],\n",
    "                  [\"USD\",\"NZD\",[], []],\n",
    "                  [\"USD\",\"SGD\",[], []]]\n",
    "\n",
    "# Run the main data collection loop\n",
    "main(currency_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5a0503d",
   "metadata": {},
   "source": [
    "## Save Output to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the long and short tables to csv\n",
    "engine = create_engine(\"sqlite+pysqlite:///../data/test.db\", echo=False, future=True)\n",
    "with engine.connect() as conn:\n",
    "    for curr in currency_pairs[:4]:\n",
    "        table = conn.execute(text(\"SELECT * FROM \"+curr[0]+curr[1]+\"_long;\"))\n",
    "        table = table.fetchall()\n",
    "        df = pd.DataFrame(table)\n",
    "        df.to_csv(f'../output_csv/{curr[0]}{curr[1]}_long.csv' ,index=False)\n",
    "    for curr in currency_pairs[4:]:\n",
    "        table = conn.execute(text(\"SELECT * FROM \"+curr[0]+curr[1]+\"_short;\"))\n",
    "        table = table.fetchall()\n",
    "        df = pd.DataFrame(table)\n",
    "        df.to_csv(f'../output_csv/{curr[0]}{curr[1]}_short.csv' ,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf6434c5a1aa7c8e434dd054297a02391e6efb1cc4c519f6d78eae818bb65a96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
